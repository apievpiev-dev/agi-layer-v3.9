#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è AGI Layer v3.9
–ó–∞–≥—Ä—É–∂–∞–µ—Ç Stable Diffusion, Phi-2, BLIP2, OCR –∏ –¥—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏
"""

import os
import sys
import asyncio
import logging
from pathlib import Path
from typing import Dict, List
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, BlipProcessor, BlipForConditionalGeneration
from diffusers import StableDiffusionPipeline
from sentence_transformers import SentenceTransformer
import easyocr
from tqdm import tqdm

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/workspace/logs/model_download.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class ModelDownloader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è AGI Layer"""
    
    def __init__(self, models_path: str = "/workspace/models"):
        self.models_path = Path(models_path)
        self.models_path.mkdir(parents=True, exist_ok=True)
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
        self.models_config = {
            # –¢–µ–∫—Å—Ç–æ–≤—ã–µ –º–æ–¥–µ–ª–∏
            "text_models": {
                "phi-2": {
                    "name": "microsoft/phi-2",
                    "type": "causal_lm",
                    "size": "2.7B",
                    "description": "–ö–æ–º–ø–∞–∫—Ç–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –æ—Ç Microsoft"
                },
                "phi-2-instruct": {
                    "name": "microsoft/phi-2",
                    "type": "causal_lm", 
                    "size": "2.7B",
                    "description": "Phi-2 –¥–ª—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π"
                }
            },
            
            # –ú–æ–¥–µ–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            "image_models": {
                "stable-diffusion-v1-5": {
                    "name": "runwayml/stable-diffusion-v1-5",
                    "type": "diffusion",
                    "size": "4GB",
                    "description": "Stable Diffusion 1.5 –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"
                }
            },
            
            # –ú–æ–¥–µ–ª–∏ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            "vision_models": {
                "blip2-base": {
                    "name": "Salesforce/blip-image-captioning-base",
                    "type": "vision_text",
                    "size": "990MB", 
                    "description": "BLIP2 –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"
                },
                "blip2-large": {
                    "name": "Salesforce/blip-image-captioning-large",
                    "type": "vision_text",
                    "size": "1.9GB",
                    "description": "BLIP2 Large –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"
                }
            },
            
            # –ú–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            "embedding_models": {
                "sentence-transformer": {
                    "name": "sentence-transformers/all-MiniLM-L6-v2",
                    "type": "sentence_transformer",
                    "size": "90MB",
                    "description": "–ú–æ–¥–µ–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"
                },
                "multilingual-e5": {
                    "name": "intfloat/multilingual-e5-small",
                    "type": "sentence_transformer", 
                    "size": "118MB",
                    "description": "–ú–Ω–æ–≥–æ—è–∑—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"
                }
            }
        }
        
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {self.device}")
    
    async def download_all_models(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π AGI Layer v3.9")
        
        total_models = sum(len(models) for models in self.models_config.values())
        logger.info(f"–í—Å–µ–≥–æ –º–æ–¥–µ–ª–µ–π –∫ –∑–∞–≥—Ä—É–∑–∫–µ: {total_models}")
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self._create_directories()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        for category, models in self.models_config.items():
            logger.info(f"\nüì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {category}")
            
            for model_key, model_info in models.items():
                try:
                    await self._download_model(category, model_key, model_info)
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {model_key}: {e}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        await self._download_additional_components()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
        self._verify_models()
        
        logger.info("‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    
    def _create_directories(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è –º–æ–¥–µ–ª–µ–π"""
        directories = [
            "text_models",
            "image_models", 
            "vision_models",
            "embedding_models",
            "ocr_models",
            "cache"
        ]
        
        for directory in directories:
            dir_path = self.models_path / directory
            dir_path.mkdir(parents=True, exist_ok=True)
            logger.info(f"üìÅ –°–æ–∑–¥–∞–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {dir_path}")
    
    async def _download_model(self, category: str, model_key: str, model_info: Dict):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        model_name = model_info["name"]
        model_type = model_info["type"]
        model_size = model_info["size"]
        
        logger.info(f"‚¨áÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞ {model_key} ({model_size}): {model_name}")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        save_path = self.models_path / category / model_key
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –ª–∏ –º–æ–¥–µ–ª—å —É–∂–µ
        if save_path.exists() and any(save_path.iterdir()):
            logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {model_key} —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
            return
        
        try:
            if model_type == "causal_lm":
                await self._download_text_model(model_name, save_path)
            elif model_type == "diffusion":
                await self._download_diffusion_model(model_name, save_path)
            elif model_type == "vision_text":
                await self._download_vision_model(model_name, save_path)
            elif model_type == "sentence_transformer":
                await self._download_embedding_model(model_name, save_path)
            
            logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {model_key} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ {model_key}: {e}")
            raise
    
    async def _download_text_model(self, model_name: str, save_path: Path):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏"""
        logger.info(f"üìù –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {model_name}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
        tokenizer = AutoTokenizer.from_pretrained(
            model_name,
            trust_remote_code=True,
            cache_dir=str(save_path)
        )
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        model = AutoModelForCausalLM.from_pretrained(
            model_name,
            torch_dtype=torch.float32,  # CPU —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
            trust_remote_code=True,
            cache_dir=str(save_path)
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ
        tokenizer.save_pretrained(str(save_path))
        model.save_pretrained(str(save_path))
        
        logger.info(f"üíæ –¢–µ–∫—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {save_path}")
    
    async def _download_diffusion_model(self, model_name: str, save_path: Path):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–∏—Ñ—Ñ—É–∑–∏–∏"""
        logger.info(f"üé® –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {model_name}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º pipeline
        pipeline = StableDiffusionPipeline.from_pretrained(
            model_name,
            torch_dtype=torch.float32,  # CPU —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
            safety_checker=None,
            requires_safety_checker=False,
            cache_dir=str(save_path)
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ
        pipeline.save_pretrained(str(save_path))
        
        logger.info(f"üíæ –ú–æ–¥–µ–ª—å –¥–∏—Ñ—Ñ—É–∑–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {save_path}")
    
    async def _download_vision_model(self, model_name: str, save_path: Path):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        logger.info(f"üëÅÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {model_name}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –∏ –º–æ–¥–µ–ª—å
        processor = BlipProcessor.from_pretrained(
            model_name,
            cache_dir=str(save_path)
        )
        
        model = BlipForConditionalGeneration.from_pretrained(
            model_name,
            torch_dtype=torch.float32,
            cache_dir=str(save_path)
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ
        processor.save_pretrained(str(save_path))
        model.save_pretrained(str(save_path))
        
        logger.info(f"üíæ –ú–æ–¥–µ–ª—å –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {save_path}")
    
    async def _download_embedding_model(self, model_name: str, save_path: Path):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        logger.info(f"üîó –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {model_name}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å sentence transformer
        model = SentenceTransformer(
            model_name,
            cache_folder=str(save_path)
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ
        model.save(str(save_path))
        
        logger.info(f"üíæ –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {save_path}")
    
    async def _download_additional_components(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        logger.info("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤...")
        
        # EasyOCR –º–æ–¥–µ–ª–∏
        try:
            logger.info("üî§ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è EasyOCR...")
            ocr_path = self.models_path / "ocr_models"
            ocr_path.mkdir(exist_ok=True)
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º EasyOCR (—ç—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∑–∏—Ç –º–æ–¥–µ–ª–∏)
            reader = easyocr.Reader(
                ['en', 'ru'],  # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π –∏ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫–∏
                model_storage_directory=str(ocr_path),
                download_enabled=True
            )
            
            logger.info("‚úÖ EasyOCR –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ EasyOCR: {e}")
    
    def _verify_models(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π...")
        
        verification_results = {}
        
        for category in self.models_config:
            category_path = self.models_path / category
            if category_path.exists():
                models_in_category = list(category_path.iterdir())
                verification_results[category] = len(models_in_category)
                logger.info(f"‚úÖ {category}: {len(models_in_category)} –º–æ–¥–µ–ª–µ–π")
            else:
                verification_results[category] = 0
                logger.warning(f"‚ö†Ô∏è {category}: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä
        total_size = sum(
            sum(f.stat().st_size for f in path.rglob('*') if f.is_file())
            for path in self.models_path.iterdir() if path.is_dir()
        )
        
        total_size_gb = total_size / (1024**3)
        logger.info(f"üìä –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π: {total_size_gb:.2f} GB")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        self._save_verification_report(verification_results, total_size_gb)
    
    def _save_verification_report(self, results: Dict, total_size: float):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ –∑–∞–≥—Ä—É–∑–∫–µ"""
        report_path = self.models_path / "download_report.txt"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("AGI Layer v3.9 - –û—Ç—á–µ—Ç –æ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–µ–π\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"–î–∞—Ç–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}\n")
            f.write(f"–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {total_size:.2f} GB\n\n")
            
            f.write("–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:\n")
            for category, count in results.items():
                f.write(f"  {category}: {count} –º–æ–¥–µ–ª–µ–π\n")
            
            f.write("\n–î–µ—Ç–∞–ª–∏ –º–æ–¥–µ–ª–µ–π:\n")
            for category, models in self.models_config.items():
                f.write(f"\n{category}:\n")
                for model_key, model_info in models.items():
                    f.write(f"  - {model_key}: {model_info['name']} ({model_info['size']})\n")
        
        logger.info(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")

    async def download_specific_models(self, model_list: List[str]):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        logger.info(f"‚¨áÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π: {model_list}")
        
        for model_key in model_list:
            found = False
            for category, models in self.models_config.items():
                if model_key in models:
                    model_info = models[model_key]
                    await self._download_model(category, model_key, model_info)
                    found = True
                    break
            
            if not found:
                logger.warning(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {model_key} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")

    def get_available_models(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        return self.models_config

    def get_download_status(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–≥—Ä—É–∑–∫–∏"""
        status = {}
        
        for category, models in self.models_config.items():
            status[category] = {}
            for model_key in models:
                model_path = self.models_path / category / model_key
                status[category][model_key] = {
                    "downloaded": model_path.exists() and any(model_path.iterdir()) if model_path.exists() else False,
                    "path": str(model_path)
                }
        
        return status


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse
    
    parser = argparse.ArgumentParser(description="–ó–∞–≥—Ä—É–∑—á–∏–∫ –º–æ–¥–µ–ª–µ–π AGI Layer v3.9")
    parser.add_argument("--models-path", default="/workspace/models", help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π")
    parser.add_argument("--specific", nargs="+", help="–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ç–æ–ª—å–∫–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏")
    parser.add_argument("--list", action="store_true", help="–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
    parser.add_argument("--status", action="store_true", help="–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏")
    
    args = parser.parse_args()
    
    downloader = ModelDownloader(args.models_path)
    
    if args.list:
        print("\nüìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:")
        models = downloader.get_available_models()
        for category, category_models in models.items():
            print(f"\n{category}:")
            for model_key, model_info in category_models.items():
                print(f"  - {model_key}: {model_info['name']} ({model_info['size']})")
        return
    
    if args.status:
        print("\nüìä –°—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏:")
        status = downloader.get_download_status()
        for category, category_models in status.items():
            print(f"\n{category}:")
            for model_key, model_status in category_models.items():
                status_icon = "‚úÖ" if model_status["downloaded"] else "‚ùå"
                print(f"  {status_icon} {model_key}")
        return
    
    if args.specific:
        await downloader.download_specific_models(args.specific)
    else:
        await downloader.download_all_models()


if __name__ == "__main__":
    from datetime import datetime
    asyncio.run(main())